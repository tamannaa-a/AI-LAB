# Resume Screening and Job Matching System

import os
import shutil
import pdfplumber
import spacy
import nltk
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Download necessary NLTK data
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

# Load Spacy model
import en_core_web_sm
nlp = en_core_web_sm.load()

# Function to preprocess text using Spacy
def spacy_preprocess(text):
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    return " ".join(tokens)

# Function to extract text from a PDF resume
def extract_text_from_pdf(pdf_path):
    with pdfplumber.open(pdf_path) as pdf:
        text = " ".join([page.extract_text() for page in pdf.pages if page.extract_text()])
    return text

# Load resume text from PDF
resume_text = extract_text_from_pdf("Tamanna (Resume).pdf")

# Define job descriptions
data = {
    "Job_Title": ["Software Engineer", "Data Analyst", "ML Engineer", "Full Stack Developer"],
    "Job_Description": [
        "Looking for a skilled Python developer experienced in Django, REST APIs, and SQL.",
        "Seeking a data analyst with experience in Excel, Power BI, and data visualization.",
        "We require someone with TensorFlow, scikit-learn, and machine learning experience.",
        "Experience with React, Node.js, and backend systems including SQL and Django."
    ]
}
job_df = pd.DataFrame(data)

# Preprocess resume and job descriptions
resume_processed = spacy_preprocess(resume_text)
job_df["Processed_Job_Description"] = job_df["Job_Description"].apply(spacy_preprocess)

# Combine resume with job descriptions for TF-IDF
all_texts = [resume_processed] + job_df["Processed_Job_Description"].tolist()

# Apply TF-IDF vectorization
vectorizer = TfidfVectorizer()
tfidf_matrix = vectorizer.fit_transform(all_texts)

# Compute cosine similarity
cosine_sim = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:]).flatten()

# Find best match
best_match_idx = cosine_sim.argmax()
best_match_score = cosine_sim[best_match_idx]
best_job_title = job_df.iloc[best_match_idx]["Job_Title"]

# Display results
print("Resume:\n", resume_text)
print("\nJob Descriptions:")
for i, row in job_df.iterrows():
    print(f"\nJob {i+1} ({row['Job_Title']}):\n{row['Job_Description']}")

print("\nSimilarity Scores:")
for i, score in enumerate(cosine_sim):
    print(f"Similarity with Job {i+1} ({job_df.iloc[i]['Job_Title']}): {score:.4f}")

print(f"\nBest matched job: {best_job_title} with similarity {best_match_score:.4f}")
